import os
import json
import logging
from base64 import urlsafe_b64encode
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime, timezone
import pytz

from .asana_client import AsanaClient
from .intent_classifier import ITIntentClassifier
from .cards import build_it_issue_card
from .email_notifier import EmailNotifier
from .knowledge_base import ITKnowledgeBase

logger = logging.getLogger(__name__)


class ITSupportService:
    """
    Orchestrates IT issue flow: card building, intent classification, and Asana task creation.
    """

    def __init__(self):
        self.asana = AsanaClient()
        self.classifier = ITIntentClassifier()
        self.email_notifier = EmailNotifier()
        # load taxonomy for cards
        self._taxonomy = self.classifier.categories
        self._recent_task_by_user: dict[str, dict] = {}
        # Reverse mapping: task_gid -> {email, issue_id, reporter_name}
        self._task_to_reporter: dict[str, dict] = {}
        self._bf_token_cache: dict[str, Any] = {}
        # Webhook handshake secret (stored after Asana sends it)
        self._webhook_secret: Optional[str] = None
        # AI åˆ†æé–‹é—œï¼ˆè¨­ True å•Ÿç”¨ AI åˆ†æå»ºè­°ï¼ŒFalse é—œé–‰ä»¥ç¯€çœ token æˆ–ç­‰å¾…ä¸²æ¥çŸ¥è­˜åº«ï¼‰
        self.enable_ai_analysis: bool = os.getenv("ENABLE_IT_AI_ANALYSIS", "false").strip().lower() == "true"
        # Dedicated model for IT issue analysis (per-call override; does not affect global model)
        self.analysis_model: str = os.getenv("IT_ANALYSIS_MODEL", "gpt-5-nano").strip()

        # Static config from env or defaults
        # Fallback to known IDs from Postman collection if envs not set
        self.workspace_gid = os.getenv("ASANA_WORKSPACE_GID", "1208041237608650")
        self.project_gid = os.getenv("ASANA_PROJECT_GID", "1208327275974093")
        self.assignee_gid = os.getenv("ASANA_ASSIGNEE_GID", "1208683560453534")
        self.assignee_section_gid = os.getenv("ASANA_ASSIGNEE_SECTION_GID", "1211277485675681")

        # Optional: map priority to Asana Tag GIDs for label display in Asana
        # Configure via env: ASANA_TAG_P1, ASANA_TAG_P2, ASANA_TAG_P3, ASANA_TAG_P4
        self.priority_tag_map: dict[str, str] = {
            "P1": os.getenv("ASANA_TAG_P1", "").strip(),
            "P2": os.getenv("ASANA_TAG_P2", "").strip(),
            "P3": os.getenv("ASANA_TAG_P3", "").strip(),
            "P4": os.getenv("ASANA_TAG_P4", "").strip(),
        }
        # Fallback: a single tag to always apply regardless of priority when mapping not set
        self.default_priority_tag_gid: str = os.getenv("ASANA_PRIORITY_TAG_GID", "").strip()

        # Initialize Knowledge Base
        try:
            from core.container import get_container
            from infrastructure.external.graph_api_client import GraphAPIClient
            graph_client = get_container().get(GraphAPIClient)
            self.knowledge_base = ITKnowledgeBase(graph_client)
        except Exception as e:
            logger.error("åˆå§‹åŒ– IT çŸ¥è­˜åº«å¤±æ•—: %s", e)
            self.knowledge_base = None

    def build_issue_card(self, language: str, reporter_name: str, reporter_email: str):
        return build_it_issue_card(language, self._taxonomy, reporter_name, reporter_email)

    async def submit_issue(self, form: Dict[str, Any], reporter_name: str, reporter_email: str) -> Dict[str, Any]:
        """
        Create Asana task from submitted form. Auto-classify if no category selected.
        Returns a dict with success, task info, and message.
        """
        description = (form.get("description") or "").strip()
        # Always classify via OpenAI (fallback to keyword classifier internally)
        category_code = ""
        priority = (form.get("priority") or "P3").strip()

        if not description:
            return {"success": False, "error": "éœ€æ±‚/å•é¡Œèªªæ˜ä¸å¾—ç‚ºç©º"}

        # AI-based classification (uses IT_ANALYSIS_MODEL); fallback to keyword classifier
        category_code, category_label = await self._classify_issue_ai(description)

        # Generate issue ID with Taiwan time
        issue_id, dt_for_id = self._generate_issue_id()

        # task name and notes
        name = f"{issue_id} - {category_label}"

        # Localize created time to Taiwan time
        taipei = pytz.timezone("Asia/Taipei")
        created_at = datetime.now(taipei).strftime("%Y-%m-%d %H:%M å°åŒ—æ™‚é–“")
        # Try AI analysis for triageï¼ˆå— enable_ai_analysis é–‹é—œæ§åˆ¶ï¼‰
        analysis_text = ""
        if self.enable_ai_analysis:
            analysis_text = await self._try_analyze_issue(description, category_label, priority)
        else:
            print("â„¹ï¸ AI åˆ†æå·²é—œé–‰ (ENABLE_IT_AI_ANALYSIS=false)")

        notes = (
            f"å–®è™Ÿ: {issue_id}\n"
            f"æå‡ºäºº: {reporter_name} <{reporter_email}>\n"
            f"åˆ†é¡: {category_label} ({category_code})\n"
            f"å„ªå…ˆé †åº: {priority}\n"
            f"å»ºç«‹ä¾†æº: TR GPT bot\n"
            f"å»ºç«‹æ™‚é–“: {created_at}\n\n"
            f"ã€éœ€æ±‚/å•é¡Œèªªæ˜ã€‘\n{description}\n"
            + ("\nã€AI åˆ†æï¼ˆå»ºè­°/æ™‚é–“/ç›¸é—œé¢å‘ï¼‰ã€‘\n\n" + analysis_text + "\n" if analysis_text else "")
        )

        # build payload following Postman spec
        data = {
            "data": {
                "name": name,
                "resource_subtype": "default_task",
                "completed": False,
                "notes": notes,
                "assignee": self.assignee_gid,
                "workspace": self.workspace_gid,
            }
        }
        # Project + section mapping
        if self.project_gid:
            data["data"]["projects"] = [self.project_gid]
            if self.assignee_section_gid:
                data["data"]["memberships"] = [
                    {"project": self.project_gid, "section": self.assignee_section_gid}
                ]

        # Add priority tag if configured
        tag_gid = self.priority_tag_map.get(priority) or self.default_priority_tag_gid
        if tag_gid:
            data["data"]["tags"] = [tag_gid]

        try:
            result = await self.asana.create_task(data)
            task = result.get("data", {})
            link = task.get("permalink_url")
            gid = task.get("gid")
            # remember for quick attachment
            if gid:
                self._recent_task_by_user[reporter_email] = {"gid": gid, "ts": datetime.now(timezone.utc)}
                # å„²å­˜åå‘æ˜ å°„ä¾› webhook å›å‘¼ä½¿ç”¨
                self._task_to_reporter[gid] = {
                    "email": reporter_email,
                    "issue_id": issue_id,
                    "reporter_name": reporter_name,
                    "task_name": name,
                    "permalink_url": link or "",
                }
            # â”€â”€ æå–®ç¢ºèª Emailï¼ˆæ¸¬è©¦éšæ®µåƒ…é€šçŸ¥æŒ‡å®šç”¨æˆ¶ï¼‰â”€â”€
            _test_emails = {"juncheng.liu@rinnai.com.tw"}
            print(f"ğŸ“§ Email æª¢æŸ¥: reporter={reporter_email.lower()}, ç™½åå–®={_test_emails}")
            if reporter_email.lower() in _test_emails:
                print(f"ğŸ“§ æº–å‚™ç™¼é€æå–®ç¢ºèª Email è‡³ {reporter_email}")
                print(f"ğŸ“§ SMTP è¨­å®š: {self.email_notifier.smtp_host}:{self.email_notifier.smtp_port}, user={self.email_notifier.smtp_user}")
                try:
                    email_ok = await self.email_notifier.send_submission_notification(
                        to_email=reporter_email,
                        issue_id=issue_id,
                        summary=description,
                        category=category_label,
                        priority=priority,
                        created_at=created_at,
                        permalink_url="",
                        reporter_name=reporter_name,
                    )
                    print(f"ğŸ“§ æå–®ç¢ºèª Email â†’ {reporter_email}: {'âœ… æˆåŠŸ' if email_ok else 'âŒ å¤±æ•—'}")
                except Exception as mail_err:
                    import traceback
                    print(f"âŒ æå–®ç¢ºèª Email ç™¼é€ä¾‹å¤–: {mail_err}")
                    traceback.print_exc()
            else:
                print(f"ğŸ“§ è·³é Email é€šçŸ¥ï¼ˆ{reporter_email} ä¸åœ¨æ¸¬è©¦ç™½åå–®ä¸­ï¼‰")
            return {
                "success": True,
                "task_gid": gid,
                "permalink_url": link,
                "issue_id": issue_id,
                "message": f"æ‚¨çš„éœ€æ±‚å·²è¢«å—ç†ï¼Œè«‹è€å¿ƒç­‰å€™ã€‚å–®è™Ÿï¼š{issue_id}"
            }
        except Exception as e:
            return {"success": False, "error": f"å»ºç«‹ Asana ä»»å‹™å¤±æ•—ï¼š{str(e)}"}

    def _generate_issue_id(self) -> tuple[str, datetime]:
        """Generate an issue ID: IT{YYYYMMDDHHMM}{seq:04d}, seq resets daily.
        Stores state in local_audit_logs/it_issue_seq.json.
        Returns (issue_id, dt).
        """
        taipei = pytz.timezone("Asia/Taipei")
        now = datetime.now(taipei)
        date_str = now.strftime("%Y%m%d")
        dt_str = now.strftime("%Y%m%d%H%M")

        base_dir = Path("local_audit_logs")
        try:
            base_dir.mkdir(parents=True, exist_ok=True)
        except Exception:
            # ignore if cannot create; fallback to in-memory behavior
            pass

        state_path = base_dir / "it_issue_seq.json"
        last_date = None
        counter = 0
        try:
            if state_path.exists():
                with state_path.open("r", encoding="utf-8") as f:
                    data = json.load(f)
                    last_date = data.get("date")
                    counter = int(data.get("counter", 0))
        except Exception:
            # reset on error
            last_date, counter = None, 0

        if last_date != date_str:
            counter = 1
        else:
            counter += 1

        try:
            with state_path.open("w", encoding="utf-8") as f:
                json.dump({"date": date_str, "counter": counter}, f)
        except Exception:
            # ignore write errors
            pass

        issue_id = f"IT{dt_str}{counter:04d}"
        return issue_id, now

    async def _try_analyze_issue(self, description: str, category_label: str, priority: str) -> str:
        """Call OpenAI to analyze the issue. Return a concise multiline text.
        On failure, return empty string.
        """
        try:
            if not description:
                return ""
            # Lazy import to avoid hard dependency cycles
            from core.container import get_container
            from infrastructure.external.openai_client import OpenAIClient

            container = get_container()
            oa: OpenAIClient = container.get(OpenAIClient)

            system = (
                "ä½ æ˜¯ä¸€ä½ä¼æ¥­ IT æœå‹™å°è³‡æ·±å·¥ç¨‹å¸«ï¼Œè«‹é‡å°ä½¿ç”¨è€…çš„ IT å•é¡Œ"
                "æä¾›ï¼š1) ç°¡çŸ­è™•ç†å»ºè­° 2) ä¼°è¨ˆè™•ç†æ™‚é–“ï¼ˆå°æ™‚/å¤©ï¼Œç°¡çŸ­ï¼‰ 3) å¯èƒ½ç›¸é—œé¢å‘ï¼ˆå¦‚å¸³è™Ÿæ¬Šé™ã€ç¶²è·¯ã€è»Ÿç¡¬é«”ã€ç³»çµ±è¨­å®šã€ä¾›æ‡‰å•†ã€è³‡æ–™åº«ã€APIã€èº«åˆ†èªè­‰ç­‰ï¼‰ã€‚"
                "è«‹åªè¼¸å‡º JSONï¼Œæ¬„ä½ç‚º recommendation, time_estimate, related_areasï¼ˆé™£åˆ—ï¼‰ã€‚èªè¨€ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚"
            )
            user = (
                f"åˆ†é¡: {category_label}\n"
                f"å„ªå…ˆé †åº: {priority}\n"
                f"æè¿°: {description}"
            )
            prompt = [
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ]
            raw = await oa.chat_completion(
                prompt,
                model=(self.analysis_model or None),
                max_tokens=600,
                temperature=0.2,
            )

            # Parse JSON
            import json as _json
            data = None
            try:
                data = _json.loads(raw)
            except Exception:
                # Try extract JSON block
                import re
                m = re.search(r"\{[\s\S]*\}", raw)
                if m:
                    try:
                        data = _json.loads(m.group(0))
                    except Exception:
                        data = None
            if isinstance(data, dict):
                rec = str(data.get("recommendation", "")).strip()
                t = str(data.get("time_estimate", "")).strip()
                areas = data.get("related_areas")
                parts = []
                if rec:
                    import re as _re
                    _rec = rec.strip()
                    if _re.search(r"\b1\)", _rec):
                        _rec = _re.sub(r"\s*(\d+\))", r"\n  \1 ", _rec).strip()
                        parts.append("- å»ºè­°ï¼š\n  " + _rec)
                    else:
                        parts.append(f"- å»ºè­°ï¼š{_rec}")
                if t:
                    parts.append(f"- æ™‚é–“ä¼°è¨ˆï¼š{t}")
                # ç›¸é—œé¢å‘åˆ†è¡Œåˆ—é»
                if isinstance(areas, list):
                    cleaned = [str(a).strip() for a in areas if str(a).strip()]
                    if cleaned:
                        area_lines = "\n".join([f"  - {a}" for a in cleaned])
                        parts.append("- ç›¸é—œé¢å‘ï¼š\n" + area_lines)
                else:
                    single_area = str(areas or "").strip()
                    if single_area:
                        parts.append(f"- ç›¸é—œé¢å‘ï¼š{single_area}")
                return "\n".join(parts).strip()
            else:
                # Fallback to raw text
                cleaned = str(raw).strip()
                if cleaned:
                    return cleaned
        except Exception:
            pass
        return ""

    async def _classify_issue_ai(self, description: str) -> tuple[str, str]:
        """Classify issue category via OpenAI using IT_ANALYSIS_MODEL.
        Returns (code, label). Falls back to keyword classifier on error.
        """
        try:
            if not description:
                return ("other", self.classifier._label_for("other"))

            from core.container import get_container
            from infrastructure.external.openai_client import OpenAIClient

            # Prepare categories for the model to choose
            allowed = [
                {"code": c.get("code", "other"), "label": c.get("label", c.get("code", "other"))}
                for c in self._taxonomy
            ]
            allowed_codes = [c["code"] for c in allowed]

            container = get_container()
            oa: OpenAIClient = container.get(OpenAIClient)

            system = (
                "ä½ æ˜¯ä¸€ä½ä¼æ¥­ IT æœå‹™å°åˆ†å–®åŠ©æ‰‹ã€‚è«‹å¾æä¾›çš„é¡åˆ¥æ¸…å–®ä¸­é¸æ“‡æœ€ç¬¦åˆçš„ä¸€å€‹é¡åˆ¥"
                "ï¼Œåªå…è¨±è¼¸å‡º JSONï¼Œæ¬„ä½ç‚º code, labelã€‚code å¿…é ˆæ˜¯æ¸…å–®ä¸­çš„ä¸€å€‹ã€‚èªè¨€ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚"
            )
            import json as _json
            user = _json.dumps({
                "categories": allowed,
                "description": description,
            }, ensure_ascii=False)

            prompt = [
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ]
            raw = await oa.chat_completion(
                prompt,
                model=(self.analysis_model or None),
                max_tokens=400,
                temperature=0.0,
            )

            data = None
            try:
                data = _json.loads(raw)
            except Exception:
                import re
                m = re.search(r"\{[\s\S]*\}", raw)
                if m:
                    try:
                        data = _json.loads(m.group(0))
                    except Exception:
                        data = None
            if isinstance(data, dict):
                code = str(data.get("code", "")).strip()
                label = str(data.get("label", "")).strip()
                if code in allowed_codes:
                    if not label:
                        label = next((c.get("label") for c in self._taxonomy if c.get("code") == code), code)
                    return (code, label)
        except Exception:
            pass

        # Fallback to keyword classifier
        return self.classifier.classify(description)

    def get_recent_task_gid(self, user_email: str) -> str | None:
        item = self._recent_task_by_user.get(user_email)
        if not item:
            return None
        return item.get("gid")

    # â”€â”€ Webhook è™•ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def handle_webhook_event(self, events: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è™•ç† Asana Webhook äº‹ä»¶ã€‚
        ç•¶åµæ¸¬åˆ°ä»»å‹™å®Œæˆæ™‚ï¼Œé€é Teams æ¨æ’­èˆ‡ Email é€šçŸ¥æå–®äººã€‚
        """
        processed = 0
        notified = 0

        for event in events:
            action = event.get("action")
            resource = event.get("resource", {})
            resource_type = resource.get("resource_type")
            logger.info("æ”¶åˆ°ç¶²é‰¤äº‹ä»¶: Action=%s, Type=%s", action, resource_type)

            # æƒ…æ³ A: ä»»å‹™ç‹€æ…‹è®Šæ›´ (ä¾‹å¦‚: å®Œæˆ)
            if action == "changed" and resource_type == "task":
                task_gid = resource.get("gid")
                if not task_gid:
                    continue
                processed += 1
                await self._handle_task_completed_event(task_gid)
                notified += 1 # é€™è£¡ç°¡åŒ–è™•ç†ï¼Œå…·é«”åœ¨å­å‡½æ•¸å…§åŸ·è¡Œ

            # æƒ…æ³ B: æ–°å¢è©•è«– (Story)
            elif action == "added" and resource_type == "story":
                parent = event.get("parent", {})
                if parent.get("resource_type") == "task":
                    task_gid = parent.get("gid")
                    story_gid = resource.get("gid")
                    await self._handle_story_added_event(task_gid, story_gid)

        return {"processed": processed, "notified": notified}

    async def _handle_task_completed_event(self, task_gid: str):
        """è™•ç†ä»»å‹™å®Œæˆå¾Œçš„é€šçŸ¥èˆ‡çŸ¥è­˜åº«å­˜æª”ã€‚"""
        try:
            task_data = await self.asana.get_task(task_gid)
            task = task_data.get("data", {})
            if not task.get("completed"):
                return
        except Exception as e:
            logger.warning("æŸ¥è©¢ Asana ä»»å‹™ %s å¤±æ•—: %s", task_gid, e)
            return

        # ç²å–æå–®äººè³‡è¨Š TR
        reporter_info = self._task_to_reporter.get(task_gid)
        if not reporter_info:
            reporter_info = self._parse_reporter_from_notes(task.get("notes", ""))
        if not reporter_info:
            return

        reporter_email = reporter_info.get("email", "")
        issue_id = reporter_info.get("issue_id", "")
        task_name = reporter_info.get("task_name") or task.get("name", "")
        permalink = reporter_info.get("permalink_url") or task.get("permalink_url", "")

        if not reporter_email:
            return

        # 1) æŠ“å–å°è©±è©•è«–å…§å®¹
        comments_str = ""
        try:
            stories_data = await self.asana.get_task_stories(task_gid)
            stories = stories_data.get("data", [])
            
            comment_list = []
            for s in stories:
                # åƒ…ç´€éŒ„æœ‰æ–‡å­—å…§å®¹çš„è©•è«–(comment)ï¼Œæ’é™¤ç³»çµ±è‡ªå‹•ç”¢ç”Ÿçš„è¨Šæ¯
                if s.get("type") == "comment" or s.get("resource_subtype") == "comment_added":
                    author = s.get("created_by", {}).get("name", "Unknown")
                    text = s.get("text", "").strip()
                    if text:
                        comment_list.append(f"**{author}**: {text}")
            
            if comment_list:
                comments_str = "\n" + "\n".join([f"  - {c}" for c in comment_list])
        except Exception as e:
            logger.warning("æŠ“å–ä»»å‹™è©•è«–å¤±æ•—: %s", e)

        # 2) Teams é€šçŸ¥
        await self._send_teams_notification(reporter_email, issue_id, task_name, permalink, comments_str)
        # 3) Email é€šçŸ¥
        await self.email_notifier.send_completion_notification(reporter_email, issue_id, task_name, permalink)

        # 4) è™•ç† IT çŸ¥è­˜åº«
        if self.knowledge_base:
            try:
                # ä½¿ç”¨å‰›æ‰æŠ“å–çš„ stories (å¦‚æœæœ‰çš„è©±)
                entry = self.knowledge_base.create_entry(task, reporter_info, stories if 'stories' in locals() else None)
                await self.knowledge_base.save_to_sharepoint(entry)
                logger.info("IT çŸ¥è­˜åº«è™•ç†å®Œæˆ: %s", issue_id)
            except Exception as kb_err:
                logger.error("è™•ç† IT çŸ¥è­˜åº«å¤±æ•—: %s", kb_err)

    async def _handle_story_added_event(self, task_gid: str, story_gid: str):
        """ç›£è½è©•è«–ï¼Œè‹¥æ˜¯ IT äººå“¡ç•™è¨€å‰‡é€šçŸ¥æå–®äººã€‚"""
        logger.info("æª¢æ¸¬åˆ°æ–°è©•è«–æ•…äº‹: Task=%s, Story=%s", task_gid, story_gid)
        try:
            # ç›´æ¥ç²å–è§¸ç™¼ Webhook çš„ Story
            story_data = await self.asana.get_story(story_gid)
            target_story = story_data.get("data", {})
            
            if not target_story:
                logger.warning("ç„¡æ³•ç²å– Story ç´°ç¯€: %s", story_gid)
                return

            # æ›´å¯¬é¬†çš„è©•è«–åˆ¤å®šï¼šæ”¯æ´ type ç‚º comment æˆ– resource_subtype ç‚º comment_added
            is_comment = target_story.get("type") == "comment" or target_story.get("resource_subtype") == "comment_added"
            
            if not is_comment:
                logger.info("å¿½ç•¥éè©•è«–é¡å‹äº‹ä»¶ (Type=%s, Subtype=%s)", 
                            target_story.get("type"), target_story.get("resource_subtype"))
                return

            comment_text = target_story.get("text", "")
            author_name = target_story.get("created_by", {}).get("name", "").strip()
            logger.info("æª¢æ¸¬åˆ°ç•™è¨€: [%s] %s...", author_name, comment_text[:20])

            # ç²å–æå–®äººè³‡è¨Š (å„ªå…ˆå¾ç·©å­˜æ‹¿ï¼Œæ‹¿ä¸åˆ°æ‰è§£æ notes)
            reporter_info = self._task_to_reporter.get(task_gid)
            if not reporter_info:
                task_data = await self.asana.get_task(task_gid)
                task = task_data.get("data", {})
                reporter_info = self._parse_reporter_from_notes(task.get("notes", ""))
            
            if not reporter_info:
                logger.warning("ç„¡æ³•å¾ä»»å‹™ %s ç²å–æå–®äººè³‡è¨Šï¼Œè·³éé€šçŸ¥", task_gid)
                return

            reporter_email = reporter_info.get("email", "")
            # ... å…¶é¤˜é‚è¼¯ä¿æŒä¸è®Š ...
            reporter_name = (reporter_info.get("reporter_name") or "").strip()
            
            # é¿å…è¿´åœˆé€šçŸ¥ï¼šå¦‚æœç•™è¨€è€…å°±æ˜¯æå–®äººï¼Œå‰‡ä¸é€šçŸ¥
            if author_name.lower() == reporter_name.lower() and reporter_name:
                logger.info("ç•™è¨€è€…ç‚ºæå–®äººæœ¬äºº (%s)ï¼Œè·³éé€šçŸ¥", author_name)
                return

            issue_id = reporter_info.get("issue_id", "UNKNOWN")
            task_name = reporter_info.get("task_name") or "IT Support Task"
            permalink = reporter_info.get("permalink_url") or ""
            
            # ç™¼é€å¤šç®¡é“é€šçŸ¥
            title = f"ã€IT é€šçŸ¥ã€‘å–®è™Ÿ {issue_id} æœ‰æ–°å›è¦†"
            link_text = f"\n\nğŸ”— [æŸ¥çœ‹ Asana ä»»å‹™]({permalink})" if permalink else ""
            msg_content = f"ğŸ”” **IT äººå“¡å·²å›è¦†æ‚¨çš„æå–®** (å–®è™Ÿ: {issue_id})\n\n**{author_name}**: {comment_text}{link_text}"
            
            # 1) Email é€šçŸ¥
            await self.email_notifier.send_custom_notification(reporter_email, title, msg_content)
            
            # 2) Teams æ¨æ’­
            await self._send_teams_push(reporter_email, msg_content)
            
            logger.info("å·²ç™¼é€è©•è«–é€šçŸ¥çµ¦æå–®äºº %s (By: %s)", reporter_email, author_name)

        except Exception as e:
            logger.error("è™•ç†è©•è«– Webhook å¤±æ•—: %s", e)

    def _parse_reporter_from_notes(self, notes: str) -> Optional[Dict[str, str]]:
        """å¾ Asana task notes ä¸­è§£ææå–®äºº email èˆ‡å–®è™Ÿã€‚
        Notes æ ¼å¼: 'å–®è™Ÿ: ITxxx\næå‡ºäºº: Name <email>\n...'
        """
        import re
        result: Dict[str, str] = {}
        try:
            # ä¿®æ”¹æ­£å‰‡è¡¨é”å¼ä»¥é©æ‡‰æ›´å¤šå¯èƒ½çš„ç©ºæ ¼æˆ–æ ¼å¼
            m_id = re.search(r"å–®è™Ÿ[:ï¼š]\s*(IT[A-Za-z0-9]+)", notes)
            if m_id:
                result["issue_id"] = m_id.group(1)
            
            m_email = re.search(r"æå‡ºäºº[:ï¼š].*?<([^>]+)>", notes)
            if m_email:
                result["email"] = m_email.group(1)
            
            m_name = re.search(r"æå‡ºäºº[:ï¼š]\s*(.+?)\s*<", notes)
            if m_name:
                result["reporter_name"] = m_name.group(1).strip()
            
            # å¾å…§å®¹ä¸­å˜—è©¦æŠ“å–åˆ†é¡ (å¦‚æœåœ¨ notes ä¸­æœ‰å¯«)
            m_cat = re.search(r"åˆ†é¡[:ï¼š]\s*(.+?)\s*\(", notes)
            if m_cat:
                result["category_label"] = m_cat.group(1).strip()
                
            m_priority = re.search(r"å„ªå…ˆé †åº[:ï¼š]\s*(\S+)", notes)
            if m_priority:
                result["priority"] = m_priority.group(1).strip()

        except Exception as e:
            logger.debug("è§£æ notes å¤±æ•—: %s", e)
        return result if result.get("email") or result.get("issue_id") else None

    async def _send_teams_notification(
        self, reporter_email: str, issue_id: str, task_name: str, permalink: str, comments: str = ""
    ) -> bool:
        """é€é Bot Framework æ¨æ’­ä»»å‹™å®Œæˆé€šçŸ¥ã€‚"""
        link_text = f"\nğŸ”— [æŸ¥çœ‹ä»»å‹™è©³æƒ…]({permalink})" if permalink else ""
        
        detail_section = ""
        if comments:
            detail_section = f"\n\nğŸ’¬ **æºé€šè©•è«–ï¼š**\n{comments}"

        message = (
            f"ğŸ‰ **æ‚¨çš„ IT æ”¯æ´å–®å·²è™•ç†å®Œæˆï¼**\n\n"
            f"ğŸ“‹ **å–®è™Ÿï¼š** {issue_id}\n"
            f"ğŸ“ **æ‘˜è¦ï¼š** {task_name}"
            f"{detail_section}"
            f"\n\n---"
            f"{link_text}"
        )
        return await self._send_teams_push(reporter_email, message)

    async def _send_teams_push(self, reporter_email: str, message: str) -> bool:
        """é€šç”¨çš„ Teams æ¨æ’­é‚è¼¯ã€‚"""
        try:
            from app import user_conversation_refs
            from botbuilder.schema import Activity, ActivityTypes

            conv_ref = user_conversation_refs.get(reporter_email)
            if not conv_ref:
                logger.info("æ‰¾ä¸åˆ° %s çš„ conversation_referenceï¼Œè·³é Teams æ¨æ’­", reporter_email)
                return False

            from core.container import get_container
            from infrastructure.bot.bot_adapter import CustomBotAdapter
            adapter: CustomBotAdapter = get_container().get(CustomBotAdapter)

            async def send_callback(turn_context):
                await turn_context.send_activity(
                    Activity(type=ActivityTypes.message, text=message)
                )

            bot_id = os.getenv("BOT_APP_ID") or os.getenv("MICROSOFT_APP_ID") or ""
            await adapter.adapter.continue_conversation(
                conv_ref, send_callback, bot_id
            )
            return True
        except Exception as e:
            logger.error("Teams æ¨æ’­å¤±æ•— (%s): %s", reporter_email, e)
            return False

    async def setup_webhook(self, target_url: str) -> Dict[str, Any]:
        """å»ºç«‹ Project å±¤ç´š Webhook è¨‚é–±ã€‚"""
        if not self.project_gid:
            return {"success": False, "error": "ASANA_PROJECT_GID æœªè¨­å®š"}
        try:
            result = await self.asana.create_webhook(self.project_gid, target_url)
            logger.info("Asana Webhook å·²å»ºç«‹: %s", result)
            return {"success": True, "data": result}
        except Exception as e:
            logger.error("å»ºç«‹ Asana Webhook å¤±æ•—: %s", e)
            return {"success": False, "error": str(e)}

    async def attach_image_from_url(self, user_email: str, url: str, filename: str, mime_type: str) -> Dict[str, Any]:
        """Download image by URL and upload to recent task for user."""
        gid = self.get_recent_task_gid(user_email)
        if not gid:
            return {"success": False, "error": "æ‰¾ä¸åˆ°æœ€è¿‘å»ºç«‹çš„ IT å–®å¯ä¾›é™„æª”ï¼Œè«‹å…ˆä½¿ç”¨ @it å»ºç«‹ã€‚"}

        import httpx
        headers: dict[str, str] = {}
        # Normalize filename: if it's exactly 'original', rename to 'original.png'
        try:
            if filename and filename.lower() == "original":
                filename = "original.png"
        except Exception:
            pass
        # For Teams/BotFramework protected URLs, try with bot token
        if self._is_botframework_protected_url(url):
            token = await self._get_botframework_token()
            if token:
                headers["Authorization"] = f"Bearer {token}"
                headers["Accept"] = "*/*"
        try:
            resp_headers = None
            content = b""
            inferred_mime = None
            if self._is_sharepoint_url(url):
                content, resp_headers, inferred_name, inferred_mime = await self._download_sharepoint_file(url)
                if inferred_name and self._is_generic_filename(filename):
                    filename = inferred_name
                if inferred_mime:
                    mime_type = inferred_mime
            else:
                async with httpx.AsyncClient(timeout=60.0, follow_redirects=True) as client:
                    resp = await client.get(url, headers=headers)
                    resp.raise_for_status()
                    resp_headers = resp.headers
                    content = resp.content
            # Try extract filename from Content-Disposition if our filename is generic
            try:
                if resp_headers:
                    cd = resp_headers.get("content-disposition") or resp_headers.get("Content-Disposition")
                    if cd and self._is_generic_filename(filename):
                        import re as _re
                        m = _re.search(r'filename\*=UTF-8''([^;\r\n]+)', cd)
                        if m:
                            from urllib.parse import unquote
                            filename = unquote(m.group(1))
                        else:
                            m = _re.search(r'filename="?([^";\r\n]+)"?', cd)
                            if m:
                                filename = m.group(1)
            except Exception:
                pass

            # If still generic, try derive extension from Content-Type header or magic
            try:
                if self._is_generic_filename(filename):
                    header_ctype = None
                    if resp_headers:
                        header_ctype = resp_headers.get("content-type") or resp_headers.get("Content-Type")
                    ctype = (header_ctype or inferred_mime or mime_type or "")
                    ctype = (ctype or "").split(";")[0].strip().lower()
                    ext_map = {
                        "image/png": "png",
                        "image/jpeg": "jpg",
                        "image/jpg": "jpg",
                        "image/gif": "gif",
                        "image/webp": "webp",
                        "image/bmp": "bmp",
                        "image/heic": "heic",
                        "application/pdf": "pdf",
                        "application/zip": "zip",
                        "text/plain": "txt",
                        "application/msword": "doc",
                        "application/vnd.openxmlformats-officedocument.wordprocessingml.document": "docx",
                        "application/vnd.ms-excel": "xls",
                        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet": "xlsx",
                        "application/vnd.ms-powerpoint": "ppt",
                        "application/vnd.openxmlformats-officedocument.presentationml.presentation": "pptx",
                    }
                    ext = ext_map.get(ctype)
                    if not ext:
                        # magic sniff
                        b = content
                        if b.startswith(b"\x89PNG\r\n\x1a\n"):
                            ext = "png"
                        elif b.startswith(b"\xff\xd8"):
                            ext = "jpg"
                        elif b.startswith(b"GIF8"):
                            ext = "gif"
                        elif b.startswith(b"RIFF") and b"WEBP" in b[:16]:
                            ext = "webp"
                        elif b.startswith(b"%PDF"):
                            ext = "pdf"
                        elif b.startswith(b"PK\x03\x04"):
                            ext = "zip"
                    if ext:
                        from datetime import datetime
                        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                        # Preserve 'original' prefix rule earlier; otherwise synthesize
                        if filename and filename.lower() == "original":
                            filename = f"original.{ext}"
                        else:
                            filename = filename if (filename and "." in filename) else f"upload_{ts}.{ext}"
            except Exception:
                pass
        except Exception as e:
            return {"success": False, "error": f"ä¸‹è¼‰é™„ä»¶å¤±æ•—ï¼š{str(e)}"}

        # æ ¹æ“šæª”æ¡ˆå…§å®¹è‡ªå‹•åµæ¸¬æ­£ç¢ºçš„å‰¯æª”åå’Œ MIME é¡å‹
        filename, mime_type = self._infer_extension_from_content(content, filename, mime_type)

        try:
            result = await self.asana.upload_attachment(gid, filename, content, mime_type)
            return {"success": True, "message": "âœ… å·²ä¸Šå‚³åœ–ç‰‡è‡³ IT å–®", "data": result}
        except Exception as e:
            return {"success": False, "error": f"ä¸Šå‚³é™„ä»¶å¤±æ•—ï¼š{str(e)}"}

    async def attach_image_bytes(self, user_email: str, content: bytes, filename: str, mime_type: str) -> Dict[str, Any]:
        """Upload raw image bytes to the user's recent task."""
        gid = self.get_recent_task_gid(user_email)
        if not gid:
            return {"success": False, "error": "æ‰¾ä¸åˆ°æœ€è¿‘å»ºç«‹çš„ IT å–®å¯ä¾›é™„æª”ï¼Œè«‹å…ˆä½¿ç”¨ @it å»ºç«‹ã€‚"}
        try:
            # æ ¹æ“šæª”æ¡ˆå…§å®¹è‡ªå‹•åµæ¸¬æ­£ç¢ºçš„å‰¯æª”åå’Œ MIME é¡å‹
            filename, mime_type = self._infer_extension_from_content(content, filename, mime_type)
            result = await self.asana.upload_attachment(gid, filename, content, mime_type)
            return {"success": True, "message": "âœ… å·²ä¸Šå‚³åœ–ç‰‡è‡³ IT å–®", "data": result}
        except Exception as e:
            return {"success": False, "error": f"ä¸Šå‚³é™„ä»¶å¤±æ•—ï¼š{str(e)}"}

    def _is_botframework_protected_url(self, url: str) -> bool:
        try:
            from urllib.parse import urlparse
            host = urlparse(url).netloc.lower()
            protected_hosts = (
                "smba.trafficmanager.net",
                "skype",
                "teams.microsoft.com",
                "api.botframework.com",
            )
            return any(h in host for h in protected_hosts)
        except Exception:
            return False

    def _is_sharepoint_url(self, url: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚º SharePoint åˆ†äº«é€£çµï¼ˆéœ€é€é Graph Shares API ä¸‹è¼‰ï¼‰ã€‚
        æ³¨æ„ï¼šç›´æ¥ä¸‹è¼‰é€£çµï¼ˆå« download.aspxã€access_tokenã€tempauth ç­‰ï¼‰ä¸éœ€è¦ç¶“é Graph APIã€‚
        """
        try:
            from urllib.parse import urlparse, parse_qs
            parsed = urlparse(url)
            host = parsed.netloc.lower()
            path = parsed.path.lower()
            query = parsed.query.lower()
            
            # ä¸æ˜¯ SharePoint/OneDrive ç¶²åŸŸ
            if not (("sharepoint.com" in host) or host.endswith("1drv.ms")):
                return False
            
            # å·²ç¶“æ˜¯ç›´æ¥ä¸‹è¼‰é€£çµï¼Œä¸éœ€è¦ Graph API
            # é€™äº› URL å·²ç¶“åŒ…å«æˆæ¬Šè³‡è¨Šï¼Œå¯ä»¥ç›´æ¥ HTTP GET
            if any(kw in path for kw in ["download.aspx", "_layouts/15/download", "/_api/"]):
                return False
            if any(kw in query for kw in ["access_token", "tempauth", "download=1"]):
                return False
            
            # æ˜¯åˆ†äº«é€£çµï¼Œéœ€è¦ç”¨ Graph API
            return True
        except Exception:
            return False

    def _is_generic_filename(self, filename: Optional[str]) -> bool:
        try:
            if not filename:
                return True
            lower = filename.lower()
            if lower in ("file", "file.bin", "image", "image.jpg", "original", "upload", "upload.bin"):
                return True
            return "." not in filename
        except Exception:
            return True

    def _infer_extension_from_content(self, content: bytes, filename: Optional[str], mime_type: Optional[str]) -> tuple[str, str]:
        """æ ¹æ“šæª”æ¡ˆå…§å®¹ï¼ˆmagic bytesï¼‰æˆ– MIME é¡å‹æ¨æ–·æ­£ç¢ºçš„å‰¯æª”åå’Œ MIME é¡å‹ã€‚
        Returns: (filename, mime_type)
        """
        from datetime import datetime

        # Magic bytes å°ç…§è¡¨
        magic_map = [
            (b"\x89PNG\r\n\x1a\n", "png", "image/png"),
            (b"\xff\xd8", "jpg", "image/jpeg"),
            (b"GIF87a", "gif", "image/gif"),
            (b"GIF89a", "gif", "image/gif"),
            (b"RIFF", "webp", "image/webp"),  # WEBP éœ€é¡å¤–æª¢æŸ¥
            (b"%PDF", "pdf", "application/pdf"),
            (b"PK\x03\x04", "zip", "application/zip"),
            (b"BM", "bmp", "image/bmp"),
        ]

        # MIME å°ç…§è¡¨
        mime_ext_map = {
            "image/png": "png",
            "image/jpeg": "jpg",
            "image/jpg": "jpg",
            "image/gif": "gif",
            "image/webp": "webp",
            "image/bmp": "bmp",
            "image/heic": "heic",
            "application/pdf": "pdf",
            "application/zip": "zip",
            "text/plain": "txt",
            "application/msword": "doc",
            "application/vnd.openxmlformats-officedocument.wordprocessingml.document": "docx",
            "application/vnd.ms-excel": "xls",
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet": "xlsx",
            "application/vnd.ms-powerpoint": "ppt",
            "application/vnd.openxmlformats-officedocument.presentationml.presentation": "pptx",
        }

        detected_ext = None
        detected_mime = None

        # å„ªå…ˆä½¿ç”¨ magic bytes åµæ¸¬
        if content:
            for magic, ext, mime in magic_map:
                if content.startswith(magic):
                    # ç‰¹æ®Šè™•ç† WEBPï¼ˆRIFF é–‹é ­ä½†éœ€ç¢ºèª WEBP æ¨™è¨˜ï¼‰
                    if ext == "webp" and b"WEBP" not in content[:16]:
                        continue
                    detected_ext = ext
                    detected_mime = mime
                    break

        # è‹¥ magic bytes æœªåµæ¸¬åˆ°ï¼Œå˜—è©¦ä½¿ç”¨ MIME é¡å‹
        if not detected_ext and mime_type:
            clean_mime = (mime_type or "").split(";")[0].strip().lower()
            detected_ext = mime_ext_map.get(clean_mime)
            if detected_ext:
                detected_mime = clean_mime

        # è‹¥ä»ç„¡æ³•åµæ¸¬ï¼Œä¿ç•™åŸå§‹å‰¯æª”å
        if not detected_ext and filename and "." in filename:
            original_ext = filename.rsplit(".", 1)[-1].lower()
            if original_ext and original_ext != "bin":
                detected_ext = original_ext

        # é è¨­ç‚º pngï¼ˆç„¡æ³•è¾¨è­˜æ™‚ï¼‰
        if not detected_ext:
            detected_ext = "png"
        if not detected_mime:
            detected_mime = "image/png"

        # ç”¢ç”Ÿæª”å
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        if filename and "." in filename:
            base = filename.rsplit(".", 1)[0]
            if base:
                final_filename = f"{base}.{detected_ext}"
            else:
                final_filename = f"upload_{ts}.{detected_ext}"
        else:
            final_filename = f"upload_{ts}.{detected_ext}"

        return final_filename, detected_mime

    def _encode_sharepoint_share_id(self, url: str) -> str:
        raw_url = (url or "").strip()
        if not raw_url:
            raise ValueError("ç„¡æ³•è½‰æ› SharePoint URL")
        encoded = urlsafe_b64encode(raw_url.encode("utf-8")).decode("utf-8").rstrip("=")
        if not encoded:
            raise ValueError("ç„¡æ³•è½‰æ› SharePoint URL")
        if encoded.startswith("u!"):
            return encoded
        return f"u!{encoded}"

    async def _download_sharepoint_file(self, url: str):
        """Download SharePoint/OneDrive item via Graph shares API."""
        import httpx
        from core.container import get_container
        from infrastructure.external.token_manager import TokenManager

        container = get_container()
        try:
            token_manager: TokenManager = container.get(TokenManager)
        except Exception as exc:
            raise RuntimeError("ç„¡æ³•å–å¾— Graph Token ç®¡ç†å™¨ï¼Œè«‹ç¢ºèªç’°å¢ƒè¨­å®šã€‚") from exc

        token = await token_manager.get_access_token()
        share_id = self._encode_sharepoint_share_id(url)
        base_url = f"https://graph.microsoft.com/v1.0/shares/{share_id}/driveItem"
        headers = {
            "Authorization": f"Bearer {token}",
            "Accept": "*/*",
        }

        metadata = None
        async with httpx.AsyncClient(timeout=60.0, follow_redirects=True) as client:
            try:
                meta_resp = await client.get(base_url, headers=headers, params={"$select": "name,file"})
            except httpx.HTTPError as err:
                raise RuntimeError(f"é€£ç·š SharePoint å¤±æ•—ï¼š{err}") from err
            if meta_resp.status_code == 200:
                metadata = meta_resp.json()
            elif meta_resp.status_code == 400:
                # 400 é€šå¸¸è¡¨ç¤ºåˆ†äº«é€£çµæ ¼å¼ä¸æ­£ç¢ºæˆ–å·²å¤±æ•ˆ
                error_detail = ""
                try:
                    error_json = meta_resp.json()
                    error_detail = error_json.get("error", {}).get("message", "")
                except Exception:
                    pass
                raise RuntimeError(f"SharePoint é€£çµç„¡æ•ˆæˆ–å·²éæœŸ (400)ï¼š{error_detail or 'è«‹é‡æ–°å–å¾—åˆ†äº«é€£çµ'}")
            elif meta_resp.status_code == 403:
                raise RuntimeError("SharePoint æ¬Šé™ä¸è¶³ (403)ï¼Œè«‹è¯çµ¡ç³»çµ±ç®¡ç†å“¡ã€‚")
            elif meta_resp.status_code == 404:
                raise RuntimeError("æ‰¾ä¸åˆ° SharePoint æª”æ¡ˆï¼Œè«‹ç¢ºèªé€£çµæ˜¯å¦ä»æœ‰æ•ˆã€‚")
            else:
                try:
                    meta_resp.raise_for_status()
                except httpx.HTTPStatusError as err:
                    raise RuntimeError(f"æŸ¥è©¢ SharePoint æª”æ¡ˆè³‡è¨Šå¤±æ•—ï¼šHTTP {err.response.status_code}") from err

            try:
                download_resp = await client.get(f"{base_url}/$value", headers=headers)
                download_resp.raise_for_status()
            except httpx.HTTPStatusError as err:
                status_code = err.response.status_code
                if status_code == 400:
                    raise RuntimeError("SharePoint ä¸‹è¼‰å¤±æ•— (400)ï¼šé€£çµæ ¼å¼ç„¡æ•ˆæˆ–å·²éæœŸï¼Œè«‹é‡æ–°åˆ†äº«æª”æ¡ˆã€‚") from err
                if status_code == 403:
                    raise RuntimeError("SharePoint ä¸‹è¼‰é­æ‹’ (403)ï¼Œè«‹ç¢ºèª BOT æ‡‰ç”¨ç¨‹å¼æ¬Šé™ã€‚") from err
                if status_code == 404:
                    raise RuntimeError("SharePoint ä¸‹è¼‰å¤±æ•—ï¼šæª”æ¡ˆä¸å­˜åœ¨æˆ–é€£çµå·²éæœŸã€‚") from err
                raise RuntimeError(f"SharePoint ä¸‹è¼‰å¤±æ•—ï¼šHTTP {status_code}") from err
            except httpx.HTTPError as err:
                raise RuntimeError(f"SharePoint ä¸‹è¼‰å¤±æ•—ï¼š{err}") from err

            inferred_name = None
            inferred_mime = None
            if metadata:
                inferred_name = metadata.get("name") or None
                file_info = metadata.get("file") or {}
                inferred_mime = file_info.get("mimeType") or None

            return download_resp.content, download_resp.headers, inferred_name, inferred_mime

    async def _get_botframework_token(self) -> str | None:
        # Cache token briefly to avoid repeated auth
        try:
            import time
            token = self._bf_token_cache.get("token")
            exp = self._bf_token_cache.get("exp", 0)
            if token and time.time() < exp - 60:
                return token

            app_id = os.getenv("BOT_APP_ID") or os.getenv("MICROSOFT_APP_ID")
            app_password = os.getenv("BOT_APP_PASSWORD") or os.getenv("MICROSOFT_APP_PASSWORD")
            if not app_id or not app_password:
                return None

            data = {
                "grant_type": "client_credentials",
                "client_id": app_id,
                "client_secret": app_password,
                "scope": "https://api.botframework.com/.default",
            }
            import httpx
            async with httpx.AsyncClient(timeout=20.0) as client:
                resp = await client.post(
                    "https://login.microsoftonline.com/botframework.com/oauth2/v2.0/token",
                    data=data,
                    headers={"Content-Type": "application/x-www-form-urlencoded"},
                )
                resp.raise_for_status()
                js = resp.json()
                token = js.get("access_token")
                expires_in = int(js.get("expires_in", 1800))
                if token:
                    self._bf_token_cache["token"] = token
                    self._bf_token_cache["exp"] = time.time() + expires_in
                    return token
        except Exception:
            return None
        return None
